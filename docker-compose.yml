version: '3'
services:
  namenode:
    container_name: namenode
    build:
      context: ./
      dockerfile: hadoop.Dockerfile
    hostname: namenode
    environment:
      - CLUSTER_NAME=hadoop-cluster
      # - HADOOP_HOME=/opt/hadoop
      # - HADOOP_LOG_DIR=/var/log/hadoop
      # - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop    
    ports:
      - "9870:9870"
    volumes:
        - ./hadoop-volumes/namenode/core-site.xml:/home/hduser/hadoop/etc/hadoop/core-site.xml
        - ./hadoop-volumes/namenode/hdfs-site.xml:/home/hduser/hadoop/etc/hadoop/hdfs-site.xml
        - ./hadoop-volumes/capacity-scheduler.xml:/home/hduser/hadoop/etc/hadoop/capacity-scheduler.xml
        - ./hadoop-volumes/mapred-site.xml:/home/hduser/hadoop/etc/hadoop/mapred-site.xml
        - ./hadoop-volumes/yarn-site.xml:/home/hduser/hadoop/etc/hadoop/yarn-site.xml    
    networks:
      - hadoop      

  spark-master:
    image: bitnami/spark:3.5.2
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"  
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077 
      # - SPARK_LOCAL_HOSTNAME=spark-driver   
      # - SPARK_LOCAL_IP=192.168.1.104   
    volumes:
      - ./hadoop-volumes/scripts:/spark/script
    networks:
      - hadoop
    # extra_hosts:
    #   - "spark-master:192.168.1.104"

  spark-worker:
    image: bitnami/spark:3.5.2
    #image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2 
      #- SPARK_LOCAL_HOSTNAME=spark-driver
      #- SPARK_LOCAL_IP=192.168.1.104
      #- SPARK_LOCAL_IP=spark-master
    networks:
      - hadoop
    # extra_hosts:
    #   - "spark-master:192.168.1.104"

  # spark-backend:
  #   container_name: spark-backend
  #   ports:
  #     - 5000:5000
  #   volumes:
  #     - ./spark-volumes/scripts:/scripts
  #   environment:
  #     - SPARK_MASTER_URL=spark://spark-master:7077   
  #     - NETFLIX_SPARK_FILE=
  #   networks:
  #     - hadoop  

networks:
  hadoop:
    driver: bridge