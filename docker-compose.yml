services:
  client:
    image: node:16
    container_name: client
    working_dir: /app
    volumes:
      - ./client:/app
    ports:
      - "3000:3000"
    command: sh -c "npm install && npm start"
  hadoop:
    #image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop
    build:
      context: ./
      dockerfile: ./dockerfile/hadoop.Dockerfile      
    ports:
      - 9870:9870
      - 9000:9000
      - 8088:8088
      - 9864:9864      
    volumes:      
      - ./data:/csv:rw      
    hostname: myhdfs
    environment:
      - CLUSTER_NAME=hadoop-cluster

  spark-master:
    image: bitnami/spark:3.5.2
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"  
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077 
      - SPARK_LOCAL_HOSTNAME=spark-master   
      - SPARK_LOCAL_IP=192.168.1.104   
    volumes:
      - ./csv:/csv:rw      
      - ./config/spark/log4j.properties:/opt/bitnami/spark/conf/log4j.properties      
    network_mode: host      

  spark-worker:
    image: bitnami/spark:3.5.2
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2 
      - SPARK_LOCAL_HOSTNAME=spark-master   
      - SPARK_LOCAL_IP=192.168.1.104   
    volumes:
      - ./config/spark/log4j.properties:/opt/bitnami/spark/conf/log4j.properties      
    network_mode: host

  # spark-backend:
  #   container_name: namenode
  #   build:
  #     context: ./
  ##     dockerfile: Dockerfile
  #   ports:
  #     - 5000:5000
  #   environment:
  #     - SPARK_MASTER_URL=spark://spark-master:7077   
  #     - NETFLIX_SPARK_FILE=
  #   networks:
  #     - hadoop  

networks:
  hadoop:
    driver: bridge
